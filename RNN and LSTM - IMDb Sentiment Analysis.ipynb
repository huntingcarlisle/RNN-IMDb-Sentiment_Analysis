{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMDb Sentiment Classification Task\n",
    "\n",
    "This data set is pulled from the **Large Movie Review Dataset** available at [Stanford Artificial Intelligence Laboratory](http://ai.stanford.edu/~amaas/data/sentiment/)\n",
    "\n",
    "It contains a set of 25,000 movie reviews for training, and 25,000 for testing. \n",
    "\n",
    "There is additional unlabeled data for use as well. Raw text and already processed bag of words formats are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM + RNN\n",
    "To counteract the vanishing gradient problem of conventional Recurrent Neural Networks, we will employ a Long Short-Term Memory (LSTM) Network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Model Architecture](Figures/Other/model_architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Input**: English-sentence movie reviews from IMDb\n",
    "- **Word Embedding Layer**: Learned Vector Representation of the Input Words\n",
    "- **LSTM Layer**: Classify the vector representations from the word embedding layer as positive or negative\n",
    "- **Dense Layer**: Transforms the LSTM output into a fully connected input to the sigmoid function, so that the final output is between 0 and 1.\n",
    "- **Output**: A probability between 0 and 1, representing the probability that the movie review is negative or positive, respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "# from lstm_utils import train_wordembed_lstm_dense_model\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Data and creating test/train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set, testing_set = imdb.load_data(num_words = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = training_set\n",
    "X_test, y_test = testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples = 25000\n",
      "Number of testing samples = 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training samples = {}\".format(X_train.shape[0]))\n",
    "print(\"Number of testing samples = {}\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zero padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_padded = sequence.pad_sequences(X_train, maxlen= 100)\n",
    "X_test_padded = sequence.pad_sequences(X_test, maxlen= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train vector shape = (25000, 100)\n",
      "X_test vector shape = (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train vector shape = {}\".format(X_train_padded.shape))\n",
    "print(\"X_test vector shape = {}\".format(X_test_padded.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration\n",
    "#### Word de-tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = imdb.get_word_index()\n",
    "word_dict = {key:(value + 3)\n",
    "             for key, value in word_to_id.items()}\n",
    "word_dict[\"<PAD>\"] = 0\n",
    "word_dict[\"<START>\"] = 1\n",
    "id_to_word = {value:key\n",
    "              for key, value in word_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example Reviews\n",
    "##### Negative Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> a rating of 1 does not begin to express how dull depressing and relentlessly bad this movie is\n"
     ]
    }
   ],
   "source": [
    "# print(\" \".join(id_to_word[id]\n",
    "#                for id in X_train[159]))\n",
    "# assert y_train[159] == 0 # Should have a negative sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Positive Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\" \".join(id_to_word[id]\n",
    "#                for id in X_train[6]))\n",
    "# assert y_train[6] == 1 # Should have a positive sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/dsp-rnn-imdb/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model.add(Embedding(input_dim = 10000,\n",
    "                    output_dim = 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(units = 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units = 1,\n",
    "                activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 128)         1280000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,411,713\n",
      "Trainable params: 1,411,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wordembed_lstm_dense_model(Optimizer, X_train, y_train, X_val, y_val):\n",
    "    \"\"\" \n",
    "    Takes as input an optimizer function, \n",
    "    returns the fit score and model\n",
    "    \"\"\"\n",
    "    # INITIALIZE MODEL\n",
    "    model = Sequential()\n",
    "    \n",
    "    # ADD LAYERS\n",
    "    # Word Embedding Layer\n",
    "    model.add(Embedding(input_dim = 10000, \n",
    "                        output_dim = 128))\n",
    "    # LSTM Layer\n",
    "    model.add(LSTM(units=128))\n",
    "    # Dense Layer\n",
    "    model.add(Dense(units=1, \n",
    "                    activation='sigmoid'))\n",
    "    \n",
    "    # COMPILE MODEL\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "                  optimizer = Optimizer, \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # TRAIN MODEL\n",
    "    scores = model.fit(X_train, \n",
    "                       y_train, \n",
    "                       batch_size=128, \n",
    "                       epochs=10, \n",
    "                       validation_data=(X_val, y_val), \n",
    "                       verbose=0)\n",
    "    \n",
    "    return scores, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RMSprop Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/dsp-rnn-imdb/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "RMSprop_score, RMSprop_model = train_wordembed_lstm_dense_model(\n",
    "                                           Optimizer = 'RMSprop',\n",
    "                                           X_train = X_train_padded,\n",
    "                                           y_train = y_train,\n",
    "                                           X_val = X_test_padded,\n",
    "                                           y_val = y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Accuracy per Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,11), \n",
    "         RMSprop_score.history['acc'], \n",
    "         label='Training Accuracy')\n",
    "\n",
    "plt.plot(range(1,11), \n",
    "         RMSprop_score.history['val_acc'], \n",
    "         label='Validation Accuracy')\n",
    "\n",
    "plt.axis([1, 10, 0, 1])\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Train and Validation Accuracy using RMSprop Optimizer')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "sns.set(font_scale=2)\n",
    "\n",
    "y_test_pred = RMSprop_model.predict_classes(X_test_padded)\n",
    "c_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "ax = sns.heatmap(c_matrix, \n",
    "                 annot=True, \n",
    "                 xticklabels=['Negative Sentiment', 'Positive Sentiment'], \n",
    "                 yticklabels=['Negative Sentiment', 'Positive Sentiment'], \n",
    "                 cbar=False, \n",
    "                 cmap='Blues', \n",
    "                 fmt='g')\n",
    "\n",
    "ax.set_xlabel(\"Prediction\")\n",
    "ax.set_ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_negatives = []\n",
    "false_positives = []\n",
    "\n",
    "for i in range(len(y_test_pred)):\n",
    "    if y_test_pred[i][0] != y_test[i]:\n",
    "        if y_test[i] == 0: # False Positive\n",
    "            false_positives.append(i)\n",
    "        else:\n",
    "            false_negatives.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
